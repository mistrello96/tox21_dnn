{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAzICN3rLqnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cd drive/'My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7xdczejJ_6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "X_train = pd.read_csv(\"tox21_dense_train.csv\")\n",
        "X_test = pd.read_csv(\"tox21_dense_test.csv\")\n",
        "Y_train = pd.read_csv(\"tox21_labels_train.csv\")\n",
        "Y_test = pd.read_csv(\"tox21_labels_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6V_MPfGNFqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop first column that contains names\n",
        "X_train = X_train.drop(X_train.columns[[0]], axis=1)\n",
        "X_test = X_test.drop(X_test.columns[[0]], axis=1)\n",
        "\n",
        "Y_train = Y_train.drop(Y_train.columns[[0]], axis=1)\n",
        "Y_test = Y_test.drop(Y_test.columns[[0]], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce0pqt0fNMP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform NaN in 0 in the labels\n",
        "Y_train = Y_train.fillna(0)\n",
        "Y_test = Y_test.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIb5irM2SGA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check if all features are numeric\n",
        "set(X_train.dtypes.append(X_test.dtypes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "905LrB1NNboE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize features in 0 mean and 1 std\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train.append(X_test).values)\n",
        "X_train = pd.DataFrame(scaler.transform(X_train.values), columns=X_train.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test.values), columns=X_test.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5nXCDuISkyF",
        "colab_type": "text"
      },
      "source": [
        "**Use only of the following method to reduce number of fatures**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdLtq27eMeun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# correlation analysis and drop correlated features\n",
        "import numpy as np\n",
        "# Create correlation matrix\n",
        "corr_matrix = X_train.corr().abs()\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "\n",
        "# Find index of feature columns with correlation greater than 0.90\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
        "print(len(to_drop))\n",
        "\n",
        "# Drop the features\n",
        "X_train.drop(X_train[to_drop], axis=1)\n",
        "X_test.drop(X_test[to_drop], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsX5l7J3P-12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PCA features reduction\n",
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "features_limit = 100\n",
        "columns = ['col' + str(x) for x in range(features_limit)]\n",
        "PCA_transformer = KernelPCA(n_components=features_limit, kernel='rbf', n_jobs=-1)\n",
        "PCA_transformer.fit(X_train.append(X_test).values)\n",
        "X_train = pd.DataFrame(PCA_transformer.transform(X_train.values), columns = columns)\n",
        "X_test = pd.DataFrame(PCA_transformer.transform(X_test.values), columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfe4cnNtTABp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "import keras.optimizers\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# AUTOENCODER\n",
        "# Define early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15, min_delta=0.001 ,restore_best_weights=True)\n",
        "\n",
        "encoding_dim1 = int(X_train.shape[1] / 2)\n",
        "encoding_dim2 = 100\n",
        "columns = ['col' + str(x) for x in range(encoding_dim2)]\n",
        "\n",
        "input_layer = Input(shape=(X_train.shape[1],))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded1 = Dense(encoding_dim1, activation='relu')(input_layer)\n",
        "bottleneck = Dense(encoding_dim2, activation='relu')(encoded1)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded1 = Dense(encoding_dim1, activation='relu')(bottleneck)\n",
        "output_layer = Dense(X_train.shape[1], activation='sigmoid')(decoded1)\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_layer, output_layer)\n",
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_layer, bottleneck)\n",
        "\n",
        "# compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='mse', metrics = ['accuracy'])\n",
        "autoencoder.summary()\n",
        "# fit the autoencoder\n",
        "autoencoder.fit(X_train.append(X_test).values, X_train.append(X_test).values, validation_split = 0.1, epochs=300, batch_size=256, verbose=True, callbacks = [es], use_multiprocessing = True)\n",
        "# extract representation\n",
        "X_train = pd.DataFrame(encoder.predict(X_train.values), columns = columns)\n",
        "X_test = pd.DataFrame(encoder.predict(X_test.values), columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGQsJNk_Mw4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train)\n",
        "print(X_test)\n",
        "\n",
        "print(Y_train)\n",
        "print(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}