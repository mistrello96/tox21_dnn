\section{Approccio e metodi utilizzati}
A seguito dell'analisi sulle feature, che ha evidenziato una correlazione tra un discreto numero di esse, sono state sviluppate e utilizzate tre differenti tecniche di \textit{feature reduction}. La prima, che ricade nella categoria delle tecniche di feature selection, si limita ad eliminare quegli elementi che risultano correlati oltre una certa soglia con altri elementi. Ponendo questa soglia a $0.90$, la dimensione dell'input si passa da $793$ a $414$ feature.\\
Le rimanenti due tecniche utilizzate, che afferiscono ai metodi di \textit{feature extraction}, sono la Principal Component Analysis (PCA) e l'utilizzo di un autoencoder; in entrambi i casi il numero di feature estratte è stato fissato a $100$.
Per quanto concerne la struttura dell'autoencoder, è stata utilizzata una topologia con 2 layer nascosti prima del \textit{bottleneck}, con funzione di attivazione \texttt{relu} e numero di neuroni dimezzato progressivamente. Come funzione di attivazione finale è stata utilizzata una funzione lineare, in quanto i valori attesi in output sono numeri reali.\\
Al fine di individuare la migliore topologia da utilizzare per il successivo processo di ottimizzazione, sono state poste a confronto tre reti dalla profondità crescente; la struttura di base si compone di $3$ layer nascosti con attivazione \texttt{relu}, dropout $0.2$ e normalizzazione prima dell'attivazione, con rispettivamente $512$, $256$ e $128$ neuroni. Ad essa sono stati aggiunti iterativamente due layer con la medesima struttura e con numero di neuroni dimezzato rispetto al livello precedente. In coda alle reti così create è stato posto un layer di output con $12$ neuroni attivati mediante una sigmoide; l'ottimizzatore utilizzato è stato \texttt{adam} (scelto per la maggiore efficienza e il \textit{learning rate} dinamico) e il parametro di peso della funzione di \textit{loss} è stato posto a $20$ (valore prossimo allo sbilanciamento complessivo tra le classi). Il fine di questa operazione è quello di determinare se una topologia più profonda della rete  sia in grado di ottenere performance migliori a parità di valori degli iperparametri.\\

Una volta individuata la migliore tra le topologie della rete proposte, è stato effettuato un processo di ottimizzazione bayesiana di alcuni iperparametri del modello. Questa tecnica, a differenza di approcci più \textit{naive}, sono \textit{sample efficient}, ovvero sfruttano al meglio il budget a disposizione per individuare la configurazione ottimale degli iperparametri. Nel processo sono stati inclusi: dimensione del \textit{batch}, valore di \textit{dropout}, valore del regolarizzazione L2, funzione di attivazione dei layer nascosti e peso della classe 1 rispetto alla classe 0.\\
Vista la presenza di variabili sia continue che categoriche, il modello surrogato selezionato è stato quello delle random forest, maggiormente adatto alla gestione di valori non continui. Il budget messo a disposizione del processo è stato fissato a 120 valutazioni, di cui il 25\% è stato utilizzato come \textit{initial design} del modello surrogato, mediante un campionamento dello spazio \textit{latin hypercube sampling} (LHS). Il valore ottimizzato dal processo è stato il valore medio dell'\textit{Area Under Curve} (AUC) sulle $12$ classi in \textit{3-fold cross validation}; la funzione di acquisizione utilizzata è stata Lower Confidence Bound.\\
Il processo di \textit{AutoML} è stato ripetuto per l'intero dataset (a seguito delle operazioni di pulizia) e per il risultato delle tre tecniche di \textit{feature refuction} presentate nel paragrafo precedente, in modo da poter individuare gli iperparametri ottimi per i vari input e rendere così le performance dei modelli confrontabili tra loro.\\

Individuata la combinazione di \textit{feature reduction} e di iperparametri in gradi di massimizzare la AUC, il modello derivante è stato analizzato più nel dettaglio, monitorando i livelli di loss durante il nuovo addestramento sull'intero dataset.
Il classificatore così ottenuto è stato utilizzato come metodo di predizione per i dati di test e le performance ottenute sono state confrontate con quelle dei modelli proposti in letteratura.\\
\todo{cosa dire della parte di AUC / precision / recall / confusion matrix?}